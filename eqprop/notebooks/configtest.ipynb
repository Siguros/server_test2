{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydra-zen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Hydra compatible cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(\"/root/workspace/EP2\", pythonpath=True)\n",
    "cfg = omegaconf.OmegaConf.load(root / \"configs\" / \"model\" / \"mnist_eqprop.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "omegaconf.OmegaConf.register_new_resolver(\"double\", lambda condition, false_value: 2 * false_value if condition else false_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.net.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_target_: src.models.eqprop_module.EqPropLitModule\n",
      "optimizer:\n",
      "  _target_: torch.optim.Adam\n",
      "  _partial_: true\n",
      "  lr: 0.001\n",
      "  weight_decay: 0.0\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
      "  _partial_: true\n",
      "  mode: min\n",
      "  factor: 0.1\n",
      "  patience: 10\n",
      "net:\n",
      "  _target_: src.models.components.eqprop_backbone.AnalogEP2\n",
      "  _partial_: true\n",
      "  input_size: ${double:${double_input}}\n",
      "  lin1_size: 128\n",
      "  output_size: 10\n",
      "  double_input: true\n",
      "  double_output: true\n",
      "  positive_w: true\n",
      "  bias: false\n",
      "  clip_weights: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(omegaconf.OmegaConf.to_yaml(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_860/528185045.py:3: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  hydra.initialize(cfg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DictConfig",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhydra\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m hydra\u001b[39m.\u001b[39;49minitialize(cfg)\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/initialize.py:81\u001b[0m, in \u001b[0;36minitialize.__init__\u001b[0;34m(self, config_path, job_name, caller_stack_depth, version_base)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         config_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 81\u001b[0m \u001b[39mif\u001b[39;00m config_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49misabs(config_path):\n\u001b[1;32m     82\u001b[0m     \u001b[39mraise\u001b[39;00m HydraException(\u001b[39m\"\u001b[39m\u001b[39mconfig_path in initialize() must be relative\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m calling_file, calling_module \u001b[39m=\u001b[39m detect_calling_file_or_module_from_stack_frame(\n\u001b[1;32m     84\u001b[0m     caller_stack_depth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     85\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/posixpath.py:62\u001b[0m, in \u001b[0;36misabs\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misabs\u001b[39m(s):\n\u001b[1;32m     61\u001b[0m     \u001b[39m\"\"\"Test whether a path is absolute\"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     s \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfspath(s)\n\u001b[1;32m     63\u001b[0m     sep \u001b[39m=\u001b[39m _get_sep(s)\n\u001b[1;32m     64\u001b[0m     \u001b[39mreturn\u001b[39;00m s\u001b[39m.\u001b[39mstartswith(sep)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DictConfig"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "\n",
    "hydra.instan(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error locating target 'src.models.eqprop_module.EqPropLitModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/utils.py:644\u001b[0m, in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(obj, part)\n\u001b[1;32m    645\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc_attr:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'src.models' has no attribute 'eqprop_module'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/utils.py:650\u001b[0m, in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     obj \u001b[39m=\u001b[39m import_module(mod)\n\u001b[1;32m    651\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:983\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:913\u001b[0m, in \u001b[0;36msource_to_code\u001b[0;34m(self, data, path, _optimize)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: cannot assign to conditional expression (eqprop_module.py, line 48)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/instantiate/_instantiate2.py:134\u001b[0m, in \u001b[0;36m_resolve_target\u001b[0;34m(target, full_key)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     target \u001b[39m=\u001b[39m _locate(target)\n\u001b[1;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/utils.py:658\u001b[0m, in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc_import:\n\u001b[0;32m--> 658\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(exc_import)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc_import\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    662\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(exc_attr)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    663\u001b[0m     \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAre you sure that \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpart\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is an attribute of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent_dotpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    664\u001b[0m ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc_attr\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Error loading 'src.models.eqprop_module.EqPropLitModule':\nSyntaxError('cannot assign to conditional expression', ('/root/workspace/EP2/src/models/eqprop_module.py', 48, 21, '        input_size, output_size * 2 if self.double_output else output_size = net.input_size, net.output_size\\n'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhydra_zen\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m hydra_zen\u001b[39m.\u001b[39;49minstantiate(cfg)\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra_zen/_hydra_overloads.py:211\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minstantiate\u001b[39m(config: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     99\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    Instantiates the target of a targeted config.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m    See :ref:`data-val` for more general data validation capabilities via hydra-zen.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m hydra_instantiate(config, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mCONVERT, ConvertMode\u001b[39m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mPARTIAL, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m instantiate_node(\n\u001b[1;32m    227\u001b[0m         config, \u001b[39m*\u001b[39;49margs, recursive\u001b[39m=\u001b[39;49m_recursive_, convert\u001b[39m=\u001b[39;49m_convert_, partial\u001b[39m=\u001b[39;49m_partial_\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39melif\u001b[39;00m OmegaConf\u001b[39m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[39m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/instantiate/_instantiate2.py:333\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    331\u001b[0m exclude_keys \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39m_target_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_convert_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_recursive_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_partial_\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m _is_target(node):\n\u001b[0;32m--> 333\u001b[0m     _target_ \u001b[39m=\u001b[39m _resolve_target(node\u001b[39m.\u001b[39;49mget(_Keys\u001b[39m.\u001b[39;49mTARGET), full_key)\n\u001b[1;32m    334\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    335\u001b[0m     is_partial \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_partial_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mor\u001b[39;00m partial\n",
      "File \u001b[0;32m~/miniconda3/envs/EP/lib/python3.9/site-packages/hydra/_internal/instantiate/_instantiate2.py:139\u001b[0m, in \u001b[0;36m_resolve_target\u001b[0;34m(target, full_key)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[39mif\u001b[39;00m full_key:\n\u001b[1;32m    138\u001b[0m             msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfull_key: \u001b[39m\u001b[39m{\u001b[39;00mfull_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 139\u001b[0m         \u001b[39mraise\u001b[39;00m InstantiationException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(target):\n\u001b[1;32m    141\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected a callable target, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(target)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error locating target 'src.models.eqprop_module.EqPropLitModule', set env var HYDRA_FULL_ERROR=1 to see chained exception."
     ]
    }
   ],
   "source": [
    "import hydra_zen\n",
    "\n",
    "hydra_zen.instantiate(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Hierachial configs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see https://github.com/mit-ll-responsible-ai/hydra-zen-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch as tr\n",
    "from hydra_zen import builds, instantiate, make_config, make_custom_builds_fn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from zen_model import UniversalFuncModule, single_layer_nn\n",
    "\n",
    "pbuilds = make_custom_builds_fn(zen_partial=True, populate_full_signature=True)\n",
    "\n",
    "OptimConf = pbuilds(Adam)\n",
    "\n",
    "LoaderConf = pbuilds(DataLoader, batch_size=25, shuffle=True, drop_last=True)\n",
    "\n",
    "ModelConf = builds(single_layer_nn, num_neurons=10)\n",
    "\n",
    "# configure our lightning module\n",
    "LitConf = pbuilds(\n",
    "    UniversalFuncModule,\n",
    "    model=ModelConf,\n",
    "    target_fn=tr.cos,\n",
    "    training_domain=builds(tr.linspace, start=-2 * math.pi, end=2 * math.pi, steps=1000),\n",
    ")\n",
    "\n",
    "TrainerConf = builds(pl.Trainer, max_epochs=100)\n",
    "\n",
    "ExperimentConfig = make_config(\n",
    "    optim=OptimConf,\n",
    "    dataloader=LoaderConf,\n",
    "    lit_module=LitConf,\n",
    "    trainer=TrainerConf,\n",
    "    seed=1,\n",
    ")\n",
    "\n",
    "\n",
    "def task_function(cfg):\n",
    "    # cfg: ExperimentConfig\n",
    "    pl.seed_everything(cfg.seed)\n",
    "\n",
    "    obj = instantiate(cfg)\n",
    "\n",
    "    # finish instantiating the lightning module, data-loader, and optimizer\n",
    "    lit_module = obj.lit_module(dataloader=obj.dataloader, optim=obj.optim)\n",
    "\n",
    "    # train the model\n",
    "    obj.trainer.fit(lit_module)\n",
    "\n",
    "    # evaluate the model over the domain to assess the fit\n",
    "    data = lit_module.training_domain\n",
    "    final_eval = lit_module.forward(data.reshape(-1, 1))\n",
    "    final_eval = final_eval.detach().cpu().numpy().ravel()\n",
    "\n",
    "    # return the final evaluation of our model:\n",
    "    # a shape-(N,) numpy-array\n",
    "    return final_eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "\n",
    "@hydra.main(config_path=\"configs\", config_name=\"model/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from src.models.eqprop_module import EqPropLitModule\n",
    "from src.models.components.eqprop_backbone import AnalogEP2\n",
    "\n",
    "class TestMnistEqprop(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.optimizer = optim.Adam(lr=0.001, weight_decay=0.0)\n",
    "        self.scheduler = lr_scheduler.ReduceLROnPlateau(mode='min', factor=0.1, patience=10)\n",
    "        self.net = AnalogEP2(input_size=2, lin1_size=128, output_size=10)\n",
    "        self.model = EqPropLitModule(self.net, self.optimizer, self.scheduler)\n",
    "\n",
    "    def test_optimizer(self):\n",
    "        self.assertIsInstance(self.model.optimizer, optim.Adam)\n",
    "        self.assertEqual(self.model.optimizer.defaults['lr'], 0.001)\n",
    "        self.assertEqual(self.model.optimizer.defaults['weight_decay'], 0.0)\n",
    "\n",
    "    def test_scheduler(self):\n",
    "        self.assertIsInstance(self.model.scheduler, lr_scheduler.ReduceLROnPlateau)\n",
    "        self.assertEqual(self.model.scheduler.mode, 'min')\n",
    "        self.assertEqual(self.model.scheduler.factor, 0.1)\n",
    "        self.assertEqual(self.model.scheduler.patience, 10)\n",
    "\n",
    "    def test_net(self):\n",
    "        self.assertIsInstance(self.model.net, AnalogEP2)\n",
    "        self.assertEqual(self.model.net.input_size, 2)\n",
    "        self.assertEqual(self.model.net.lin1_size, 128)\n",
    "        self.assertEqual(self.model.net.output_size, 10)\n",
    "\n",
    "    def test_double_input(self):\n",
    "        self.assertEqual(self.model.net.input_size, 4)\n",
    "\n",
    "    def test_double_output(self):\n",
    "        self.assertEqual(self.model.net.output_size, 20)\n",
    "\n",
    "    def test_positive_w(self):\n",
    "        self.assertTrue((self.model.net.w > 0).all())\n",
    "\n",
    "    def test_bias(self):\n",
    "        self.assertIsNone(self.model.net.b)\n",
    "\n",
    "    def test_clip_weights(self):\n",
    "        self.assertTrue((self.model.net.w.abs() <= 1).all())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from src.models.eqprop_module import EqPropLitModule\n",
    "from src.models.components.eqprop_backbone import AnalogEP2\n",
    "\n",
    "@pytest.fixture\n",
    "def eqprop_model():\n",
    "    optimizer = optim.Adam(lr=0.001, weight_decay=0.0)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(mode='min', factor=0.1, patience=10)\n",
    "    net = AnalogEP2(input_size=2, lin1_size=128, output_size=10)\n",
    "    model = EqPropLitModule(net, optimizer, scheduler)\n",
    "    return model\n",
    "\n",
    "def test_optimizer(eqprop_model):\n",
    "    assert isinstance(eqprop_model.optimizer, optim.Adam)\n",
    "    assert eqprop_model.optimizer.defaults['lr'] == 0.001\n",
    "    assert eqprop_model.optimizer.defaults['weight_decay'] == 0.0\n",
    "\n",
    "def test_scheduler(eqprop_model):\n",
    "    assert isinstance(eqprop_model.scheduler, lr_scheduler.ReduceLROnPlateau)\n",
    "    assert eqprop_model.scheduler.mode == 'min'\n",
    "    assert eqprop_model.scheduler.factor == 0.1\n",
    "    assert eqprop_model.scheduler.patience == 10\n",
    "\n",
    "def test_net(eqprop_model):\n",
    "    assert isinstance(eqprop_model.net, AnalogEP2)\n",
    "    assert eqprop_model.net.input_size == 2\n",
    "    assert eqprop_model.net.lin1_size == 128\n",
    "    assert eqprop_model.net.output_size == 10\n",
    "\n",
    "def test_double_input(eqprop_model):\n",
    "    assert eqprop_model.net.input_size == 4\n",
    "\n",
    "def test_double_output(eqprop_model):\n",
    "    assert eqprop_model.net.output_size == 20\n",
    "\n",
    "def test_positive_w(eqprop_model):\n",
    "    assert (eqprop_model.net.w > 0).all()\n",
    "\n",
    "def test_bias(eqprop_model):\n",
    "    assert eqprop_model.net.b is None\n",
    "\n",
    "def test_clip_weights(eqprop_model):\n",
    "    assert (eqprop_model.net.w.abs() <= 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from src.models.eqprop_module import EqPropLitModule\n",
    "\n",
    "@hydra.main(config_path='conf', config_name='config')\n",
    "def test_eqprop(cfg):\n",
    "    optimizer = optim.Adam(lr=cfg.optimizer.lr, weight_decay=cfg.optimizer.weight_decay)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(mode=cfg.scheduler.mode, factor=cfg.scheduler.factor, patience=cfg.scheduler.patience)\n",
    "    net = hydra.utils.instantiate(cfg.net)\n",
    "    model = EqPropLitModule(net, optimizer, scheduler)\n",
    "\n",
    "    assert isinstance(model.optimizer, optim.Adam)\n",
    "    assert model.optimizer.defaults['lr'] == cfg.optimizer.lr\n",
    "    assert model.optimizer.defaults['weight_decay'] == cfg.optimizer.weight_decay\n",
    "\n",
    "    assert isinstance(model.scheduler, lr_scheduler.ReduceLROnPlateau)\n",
    "    assert model.scheduler.mode == cfg.scheduler.mode\n",
    "    assert model.scheduler.factor == cfg.scheduler.factor\n",
    "    assert model.scheduler.patience == cfg.scheduler.patience\n",
    "\n",
    "    assert isinstance(model.net, hydra.types.Instantiable)\n",
    "    assert model.net.input_size == cfg.net.input_size\n",
    "    assert model.net.lin1_size == cfg.net.lin1_size\n",
    "    assert model.net.output_size == cfg.net.output_size\n",
    "\n",
    "    if cfg.double_input:\n",
    "        assert model.net.input_size == cfg.net.input_size * 2\n",
    "    else:\n",
    "        assert model.net.input_size == cfg.net.input_size\n",
    "\n",
    "    if cfg.double_output:\n",
    "        assert model.net.output_size == cfg.net.output_size * 2\n",
    "    else:\n",
    "        assert model.net.output_size == cfg.net.output_size\n",
    "\n",
    "    if cfg.positive_w:\n",
    "        assert (model.net.w > 0).all()\n",
    "    else:\n",
    "        assert (model.net.w <= 0).any()\n",
    "\n",
    "    if cfg.bias:\n",
    "        assert model.net.b is not None\n",
    "    else:\n",
    "        assert model.net.b is None\n",
    "\n",
    "    if cfg.clip_weights:\n",
    "        assert (model.net.w.abs() <= 1).all()\n",
    "    else:\n",
    "        assert (model.net.w.abs() > 1).any()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_eqprop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('EP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "90e4321df57dcdaa38923c918cbc297c2df4b63e34e944f71f9cbb193a1f4ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
