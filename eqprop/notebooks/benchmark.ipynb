{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref) https://pytorch.org/tutorials/recipes/recipes/benchmark.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagmul(mat, diag):\n",
    "    return mat * diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "A = torch.randn(256, 256)\n",
    "d = torch.randn(256)\n",
    "num_threads = torch.get_num_threads()\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"torch.matmul(A, torch.diag(d))\", globals={\"d\": d, \"A\": A}, num_threads=num_threads\n",
    ").blocked_autorange(min_run_time=1)\n",
    "t1 = benchmark.Timer(\n",
    "    stmt=\"diagmul(d, A)\",\n",
    "    setup=\"from __main__ import diagmul\",\n",
    "    globals={\"d\": d, \"A\": A},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A * d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matmul: \", t0)\n",
    "print(\"Diagmul: \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = benchmark.Timer(\n",
    "    stmt=\"d.mul(A)\", globals={\"d\": d, \"A\": A}, num_threads=num_threads\n",
    ").blocked_autorange(min_run_time=1)\n",
    "print(\"Matmul: \", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "results = []\n",
    "sizes = [1, 64, 1024]\n",
    "for m, n in product(sizes, sizes):\n",
    "    # label and sub_label are the rows\n",
    "    # description is the column\n",
    "    label = \"Diagonal matrix multiplication\"\n",
    "    sub_label = f\"[{m}, {n}]\"\n",
    "    A = torch.rand((m, n))\n",
    "    d = torch.rand(n)\n",
    "    for num_threads in [1, 4, 8]:\n",
    "        results.append(\n",
    "            benchmark.Timer(\n",
    "                stmt=\"torch.matmul(A, torch.diag(d))\",\n",
    "                globals={\"d\": d, \"A\": A},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description=\"mm\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "        )\n",
    "        results.append(\n",
    "            benchmark.Timer(\n",
    "                stmt=\"diagmul(A,d)\",\n",
    "                setup=\"from __main__ import diagmul\",\n",
    "                globals={\"d\": d, \"A\": A},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description=\"vm\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "        )\n",
    "\n",
    "compare = benchmark.Compare(results)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
