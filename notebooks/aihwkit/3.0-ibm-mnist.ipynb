{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# (C) Copyright 2020, 2021, 2022, 2023, 2024 IBM. All Rights Reserved.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "\n",
    "\"\"\"aihwkit example 3: MNIST training.\n",
    "\n",
    "MNIST training example based on the paper:\n",
    "https://www.frontiersin.org/articles/10.3389/fnins.2016.00333/full\n",
    "\n",
    "Uses learning rates of η = 0.01, 0.005, and 0.0025\n",
    "for epochs 0–10, 11–20, and 21–30, respectively.\n",
    "\"\"\"\n",
    "# pylint: disable=invalid-name, redefined-outer-name\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "# Imports from PyTorch.\n",
    "import torch\n",
    "\n",
    "# Imports from aihwkit.\n",
    "from aihwkit.nn import AnalogLinear, AnalogSequential\n",
    "from aihwkit.optim import AnalogSGD\n",
    "from aihwkit.simulator.configs import ConstantStepDevice, SingleRPUConfig\n",
    "from aihwkit.simulator.rpu_base import cuda\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Check device\n",
    "USE_CUDA = 0\n",
    "if cuda.is_compiled():\n",
    "    USE_CUDA = 1\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "# Path where the datasets will be stored.\n",
    "PATH_DATASET = os.path.join(\"data\", \"DATASET\")\n",
    "\n",
    "# Network definition.\n",
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZES = [256, 128]\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "# Training parameters.\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "def load_images():\n",
    "    \"\"\"Load images for train from the torchvision datasets.\"\"\"\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # Load the images.\n",
    "    train_set = datasets.MNIST(PATH_DATASET, download=True, train=True, transform=transform)\n",
    "    val_set = datasets.MNIST(PATH_DATASET, download=True, train=False, transform=transform)\n",
    "    train_data = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validation_data = torch.utils.data.DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return train_data, validation_data\n",
    "\n",
    "\n",
    "def create_analog_network(input_size, hidden_sizes, output_size):\n",
    "    \"\"\"Create the neural network using analog and digital layers.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): size of the Tensor at the input.\n",
    "        hidden_sizes (list): list of sizes of the hidden layers (2 layers).\n",
    "        output_size (int): size of the Tensor at the output.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: created analog model\n",
    "    \"\"\"\n",
    "    model = AnalogSequential(\n",
    "        AnalogLinear(\n",
    "            input_size,\n",
    "            hidden_sizes[0],\n",
    "            True,\n",
    "            rpu_config=SingleRPUConfig(device=ConstantStepDevice()),\n",
    "        ),\n",
    "        nn.Sigmoid(),\n",
    "        AnalogLinear(\n",
    "            hidden_sizes[0],\n",
    "            hidden_sizes[1],\n",
    "            True,\n",
    "            rpu_config=SingleRPUConfig(device=ConstantStepDevice()),\n",
    "        ),\n",
    "        nn.Sigmoid(),\n",
    "        AnalogLinear(\n",
    "            hidden_sizes[1],\n",
    "            output_size,\n",
    "            True,\n",
    "            rpu_config=SingleRPUConfig(device=ConstantStepDevice()),\n",
    "        ),\n",
    "        nn.LogSoftmax(dim=1),\n",
    "    )\n",
    "\n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_sgd_optimizer(model):\n",
    "    \"\"\"Create the analog-aware optimizer.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model to be trained.\n",
    "    Returns:\n",
    "        nn.Module: optimizer\n",
    "    \"\"\"\n",
    "    optimizer = AnalogSGD(model.parameters(), lr=0.05)\n",
    "    optimizer.regroup_param_groups(model)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train(model, train_set):\n",
    "    \"\"\"Train the network.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model to be trained.\n",
    "        train_set (DataLoader): dataset of elements to use as input for training.\n",
    "    \"\"\"\n",
    "    classifier = nn.NLLLoss()\n",
    "    optimizer = create_sgd_optimizer(model)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    time_init = time()\n",
    "    for epoch_number in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_set:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            # Flatten MNIST images into a 784 vector.\n",
    "            images = images.view(images.shape[0], -1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Add training Tensor to the model (input).\n",
    "            output = model(images)\n",
    "            loss = classifier(output, labels)\n",
    "\n",
    "            # Run training (backward propagation).\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize weights.\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(\"Epoch {} - Training loss: {:.16f}\".format(epoch_number, total_loss / len(train_set)))\n",
    "\n",
    "        # Decay learning rate if needed.\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"\\nTraining Time (s) = {}\".format(time() - time_init))\n",
    "\n",
    "\n",
    "def test_evaluation(model, val_set):\n",
    "    \"\"\"Test trained network\n",
    "\n",
    "    Args:\n",
    "        model (nn.Model): Trained model to be evaluated\n",
    "        val_set (DataLoader): Validation set to perform the evaluation\n",
    "    \"\"\"\n",
    "    # Setup counter of images predicted to 0.\n",
    "    predicted_ok = 0\n",
    "    total_images = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in val_set:\n",
    "        # Predict image.\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        pred = model(images)\n",
    "\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total_images += labels.size(0)\n",
    "        predicted_ok += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"\\nNumber Of Images Tested = {}\".format(total_images))\n",
    "    print(\"Model Accuracy = {}\".format(predicted_ok / total_images))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load datasets.\n",
    "    train_dataset, validation_dataset = load_images()\n",
    "\n",
    "    # Prepare the model.\n",
    "    model = create_analog_network(INPUT_SIZE, HIDDEN_SIZES, OUTPUT_SIZE)\n",
    "\n",
    "    # Train the model.\n",
    "    train(model, train_dataset)\n",
    "\n",
    "    # Evaluate the trained model.\n",
    "    test_evaluation(model, validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
