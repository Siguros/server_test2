{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../../EP2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import DictConfig, open_dict\n",
    "\n",
    "\n",
    "def get_cfg():\n",
    "    with initialize(version_base=\"1.2\", config_path=\"../../EP2/configs\"):\n",
    "        cfg = compose(config_name=\"train.yaml\", return_hydra_config=True, overrides=[])\n",
    "        with open_dict(cfg):\n",
    "            cfg.paths.root_dir = str(pyrootutils.find_root())\n",
    "            cfg.trainer.max_epochs = 1\n",
    "            cfg.trainer.limit_train_batches = 0.01\n",
    "            cfg.trainer.limit_val_batches = 0.1\n",
    "            cfg.trainer.limit_test_batches = 0.1\n",
    "            cfg.trainer.accelerator = \"cpu\"\n",
    "            cfg.trainer.devices = 1\n",
    "            cfg.datamodule.num_workers = 0\n",
    "            cfg.datamodule.pin_memory = False\n",
    "            cfg.datamodule.batch_size = 1\n",
    "            cfg.extras.print_config = False\n",
    "            cfg.extras.enforce_tags = False\n",
    "            cfg.logger = None\n",
    "\n",
    "        return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def print_pretty_json(json_obj):\n",
    "    print(json.dumps(json_obj, indent=4, sort_keys=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton solver 1 vs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src._eqprop.eqprop_backbone import AnalogEP, AnalogEP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = torch.rand(1, 784).clamp_min(0.01), torch.randint(0, 10, (1,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep2 = AnalogEP2(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from src.rqprop.eqprop_util import init_params\n",
    "\n",
    "ep2.model.apply(partial(init_params, min=1e-5, max=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "ep2.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ep2.model.named_buffers())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.datamodule.batch_size\n",
    "ep1 = AnalogEP(cfg.datamodule.batch_size, pos_W=True, L=[1e-5] * 2, U=[1] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nodes = ep1.minimize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# condition number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize weights\n",
    "import torch\n",
    "\n",
    "w = torch.randn(28, 28)\n",
    "plt.imshow(w, cmap=\"viridis\")\n",
    "# add colorbar\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check matrix spectral density\n",
    "w = torch.randn(10000, 10000)\n",
    "# find eigenvalues\n",
    "eigvals = torch.linalg.eigvals(w)\n",
    "\n",
    "# plot histogram\n",
    "plt.hist(eigvals, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot marchenko-pastur distribution\n",
    "import numpy as np\n",
    "\n",
    "sigma = 1\n",
    "m = 1000\n",
    "n = 100\n",
    "ratio = m / n\n",
    "\n",
    "X = np.random.normal(0, sigma, (m, n))\n",
    "# singular values\n",
    "s = np.linalg.svd(X, compute_uv=False) / n\n",
    "\n",
    "\n",
    "def mu_plus_minus(sigma, ratio, s):\n",
    "    return sigma * (1 + np.sqrt(ratio)) ** 2, sigma * (1 - np.sqrt(ratio)) ** 2\n",
    "\n",
    "\n",
    "plt.hist(s, bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VS scipy.optimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# load model checkpoint\n",
    "ckpt = torch.load(\"../logs/train/runs/2023-07-13_17-53-04/checkpoints/epoch_002.ckpt\")\n",
    "# get weights from lin1 & last layers\n",
    "w1 = ckpt[\"state_dict\"][\"net.model.lin1.weight\"]\n",
    "w2 = ckpt[\"state_dict\"][\"net.model.last.weight\"]\n",
    "# get biases from lin1 & last layers\n",
    "b1 = ckpt[\"state_dict\"][\"net.model.lin1.bias\"]\n",
    "b2 = ckpt[\"state_dict\"][\"net.model.last.bias\"]\n",
    "# get input & output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.shape, w2.shape, b1.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample input from MNIST dataset\n",
    "from src.data.mnist_datamodule import MNISTDataModule\n",
    "\n",
    "dm = MNISTDataModule(batch_size=1, data_dir=\"../data\")\n",
    "dm.setup()\n",
    "x, y = next(iter(dm.train_dataloader()))\n",
    "from src._eqprop.eqprop_module import EqPropLitModule\n",
    "\n",
    "x = EqPropLitModule.preprocessing_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.eqprop.eqprop_util import OTS, P3OTS\n",
    "from src.eqprop.E_minimizer import _stepsolve2\n",
    "\n",
    "dims = [2 * 28 * 28, 128, 10 * 2]\n",
    "W = [w1, w2]\n",
    "B = [b1, b2]\n",
    "v1 = _stepsolve2(x, W, dims, B, i_ext=0, OTS=OTS(), max_iter=30, atol=1e-6)\n",
    "v2 = _stepsolve2(x, W, dims, B, i_ext=0, OTS=P3OTS(), max_iter=30, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_stepsolve2(x, W, [28 * 28 * 2, 128, 10 * 2], B, i_ext=0, OTS=P3OTS(), max_iter=30, atol=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stepsolve2(x, W, dims, B, i_ext=0, OTS=OTS(), max_iter=30, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = sum(dims[1:])\n",
    "# construct the laplacian\n",
    "paddedG = [torch.zeros(dims[1], size).type_as(x)]\n",
    "for i, g in enumerate(W[1:]):\n",
    "    paddedG.append(torch.functional.pad(-g, (sum(dims[1 : i + 1]), sum(dims[2 + i :]))))\n",
    "\n",
    "Ll = torch.cat(paddedG, dim=-2)\n",
    "L = Ll + Ll.mT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = v1.split(dims[1:], dim=1)[1].squeeze()\n",
    "(yhat[::2] - yhat[1::2]).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.eqprop.eqprop_util import OTS, P3OTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ots = OTS(Vl=-0, Vr=0, Is=1e-6, Vth=0.026)\n",
    "p3ots = P3OTS(Vl=-0, Vr=0, Is=1e-6, Vth=0.026)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the OTS function\n",
    "import torch\n",
    "\n",
    "x = torch.linspace(-1, 1, 100)\n",
    "plt.plot(x, ots.i(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# find the root of the OTS function using Newton's method\n",
    "from scipy.optimize import fsolve, root\n",
    "\n",
    "\n",
    "def np_wrapper(x: np.ndarray):\n",
    "    x = torch.tensor(x)\n",
    "    return p3ots.i(x).detach().numpy()\n",
    "\n",
    "\n",
    "x0 = np.random.rand(1000) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "res, info, _, __ = fsolve(np_wrapper, x0=x, full_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "residuals_history = {}\n",
    "duration_history = {}\n",
    "methods = [\n",
    "    \"krylov\",\n",
    "    \"df-sane\",\n",
    "]  # , 'broyden1', 'broyden2', 'anderson', 'linearmixing', 'diagbroyden', 'excitingmixing']\n",
    "\n",
    "\n",
    "def callback(residual, method):\n",
    "    if method not in residuals_history:\n",
    "        residuals_history[method] = []\n",
    "        duration_history[method] = []\n",
    "        t = time.time()\n",
    "    new_t = time.time() - t\n",
    "    duration_history[method].append(new_t)\n",
    "    residuals_history[method].append(np.linalg.norm(residual, ord=np.inf))\n",
    "    t = time.time()\n",
    "\n",
    "\n",
    "def modified_callback(x, residual=None, method=None):\n",
    "    if residual is None:\n",
    "        residual = x\n",
    "    callback(residual, method)\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    residuals_history[method] = []  # Reset the residuals history for each method\n",
    "    try:\n",
    "        sol = root(\n",
    "            np_wrapper,\n",
    "            np.random.rand(10),\n",
    "            method=method,\n",
    "            callback=lambda x, res=None: modified_callback(x, res, method),\n",
    "            options={\"fatol\": 1e-7, \"disp\": True},\n",
    "        )\n",
    "    except Exception:\n",
    "        # Some methods might still not accept the callback or might throw other errors\n",
    "        print(f\"skip {method}\")\n",
    "\n",
    "# Plotting the residuals at each step\n",
    "plt.figure(figsize=(14, 7))\n",
    "# colors = plt.cm.get_cmap('tab10').colors\n",
    "for idx, (method, res) in enumerate(residuals_history.items()):\n",
    "    if res:  # Only plot methods that have residuals recorded\n",
    "        # delete outliers\n",
    "        t = np.array(duration_history[method])\n",
    "        res = np.array(res)\n",
    "        res[res > 1e4] = np.nan\n",
    "        res = res[~np.isnan(res)]\n",
    "        plt.plot(t, res, label=method, marker=\"o\", markersize=5)\n",
    "\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Convergence of Residuals for Different Methods\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import root\n",
    "\n",
    "\n",
    "# Define the function using numpy again\n",
    "def i_numpy(x):\n",
    "    x = torch.tensor(x)\n",
    "    return p3ots.i(x).detach().numpy()\n",
    "\n",
    "\n",
    "# Define the methods to test\n",
    "methods_to_test = [\"hybr\", \"lm\", \"df-sane\", \"krylov\"]\n",
    "\n",
    "\n",
    "def maxiter_method(method):\n",
    "    if method in [\"krylov\", \"lm\"]:\n",
    "        return {\"maxiter\": 7 if method == \"krylov\" else 10}\n",
    "    elif method in [\"hybr\", \"df-sane\"]:\n",
    "        return {\"maxfev\": 1500 if method == \"df-sane\" else 40}\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Find roots and record the elapsed time and final residuals again\n",
    "elapsed_time_results = {}\n",
    "residuals_results = {}\n",
    "\n",
    "for method in methods_to_test:\n",
    "    start_time = time.time()\n",
    "    sol = root(i_numpy, x0=np.random.rand(100) * 2, method=method, options=maxiter_method(method))\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time_results[method] = end_time - start_time\n",
    "    residuals_results[method] = np.abs(sol.fun[0])\n",
    "\n",
    "# Plotting the results again\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "ax1.bar(\n",
    "    elapsed_time_results.keys(),\n",
    "    elapsed_time_results.values(),\n",
    "    color=[\"blue\", \"red\", \"green\", \"purple\"],\n",
    ")\n",
    "ax1.set_ylabel(\"Elapsed Time (seconds)\")\n",
    "ax1.set_title(\"Elapsed Time for Different Methods\")\n",
    "\n",
    "ax2.bar(\n",
    "    residuals_results.keys(), residuals_results.values(), color=[\"blue\", \"red\", \"green\", \"purple\"]\n",
    ")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_ylabel(\"Final Residuals\")\n",
    "ax2.set_title(\"Final Residuals for Different Methods\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScipyStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.eqprop.strategy import ScipyStrategy\n",
    "\n",
    "st = ScipyStrategy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTS-stability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diode model\n",
    "\n",
    "I-V curve\n",
    "I = Is*(exp((V)/Vt)-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piecewise linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.eqprop import eqprop_util\n",
    "\n",
    "x = torch.linspace(-1.0, 1.0, 100)\n",
    "ots = eqprop_util.OTS(Vl=-0, Vr=0, Is=1e-6, Vth=0.026)\n",
    "p3ots = eqprop_util.P3OTS(Vl=-0, Vr=0, Is=1e-6, Vth=0.026)\n",
    "y = ots.i(x)\n",
    "y2 = p3ots.i(x)\n",
    "# y4 = eqprop_util.rectifier_poly_i(x, power=3)\n",
    "plt.plot(x, y, label=\"exponential\")\n",
    "plt.plot(x, y2, label=\"quadratic\")\n",
    "# plt.plot(x, y4, label=\"cubic\")\n",
    "# add a legend\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symtanh = eqprop_util.Symtanh(Vl=0.3, Vr=0.7, Is=1, Vth=0.2)\n",
    "y = symtanh.i(x)\n",
    "b = symtanh.a(x)\n",
    "plt.plot(x, y, label=\"symtanh\")\n",
    "plt.plot(x, b, label=\"symtanh a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-2.2, 2.2, 100)\n",
    "# plt.plot(x, rectifier_pseudo_g(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.exp() - (-x).exp()\n",
    "p2 = (1 + x + x.pow(2) / 2) - (1 - x + x.pow(2) / 2)\n",
    "p4 = (1 + x + x.pow(2) / 2 + x.pow(3) / 6) - (1 - x + x.pow(2) / 2 - x.pow(3) / 6)\n",
    "plt.plot(x, y, label=\"exponential\")\n",
    "plt.plot(x, p2, label=\"piecewise linear\")\n",
    "plt.plot(x, p4, label=\"piecewise linear\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SymOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.core.eqprop.eqprop_util import OTS, P3OTS, SymOTS\n",
    "\n",
    "ots = OTS(Vl=-0.5, Vr=0.5)\n",
    "symots = SymOTS(Vl=-0.5, Vr=0.5)\n",
    "\n",
    "x = torch.logspace(-0.01, 0.01, 3000)\n",
    "\n",
    "inv_a1 = 1 / ots.a(x)\n",
    "inv_a2 = 1 / symots.a(x)\n",
    "inv_a3 = symots.inv_a(x)\n",
    "\n",
    "\n",
    "idiva = ots.i(x) / ots.a(x)\n",
    "idiva2 = symots.i_div_a(x)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(x, idiva, label=\"exponential\")\n",
    "plt.plot(x, idiva2 - idiva, label=\"exponential\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmexp(V):\n",
    "    xr = (V - 0.5) / 0.026\n",
    "    xl = (-V - 0.5) / 0.026\n",
    "    xmax = torch.max(xr, xl)\n",
    "    return 0.026 * (\n",
    "        (torch.exp(xr - xmax) - torch.exp(xl - xmax))\n",
    "        / (torch.exp(xr - xmax) + torch.exp(xl - xmax))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, maxmexp(x) - idiva2, label=\"exponential\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block Cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a block laplacian matrix\n",
    "import torch\n",
    "import torch.linalg as la\n",
    "\n",
    "A = torch.randn(3, 3)\n",
    "Lap = torch.cat(\n",
    "    [\n",
    "        torch.cat([torch.diag(A.sum(dim=1)), -A], dim=1),\n",
    "        torch.cat([-A.T, torch.diag(A.sum(dim=0))], dim=1),\n",
    "    ],\n",
    "    dim=0,\n",
    ")\n",
    "\n",
    "\n",
    "def add_to_laplacian(Lap: torch.Tensor, A: torch.Tensor):\n",
    "    m, n = A.shape\n",
    "    Lap[:-m, :-n] += torch.diag(A.sum(dim=1))\n",
    "    return torch.cat(\n",
    "        [\n",
    "            torch.cat([torch.diag(A.sum(dim=1)), -A], dim=1),\n",
    "            torch.cat([-A.T, torch.diag(A.sum(dim=0))], dim=1),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "\n",
    "for _ in range(3):\n",
    "    A = torch.randn(3, 3)\n",
    "    Lap = add_to_laplacian(Lap, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def block_tri_cholesky(W: list[torch.Tensor]):\n",
    "    \"\"\"Blockwise cholesky decomposition for a size varying block tridiagonal matrix.\n",
    "    see spftrf() in LAPACK\n",
    "\n",
    "    Args:\n",
    "        W (List[torch.Tensor]): List of lower triangular blocks.\n",
    "\n",
    "    Returns:\n",
    "        L (List[torch.Tensor]): List of lower triangular blocks.\n",
    "        C (List[torch.Tensor]): List of diagonal blocks. as column vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(W)\n",
    "    C = [torch.zeros_like(W[i]) for i in range(n)]\n",
    "    L = [None] * (n + 1)\n",
    "    W.append(0)\n",
    "    L[0] = torch.cholesky(W[0])\n",
    "    for i in range(n):\n",
    "        C[i] = torch.triangular_solve(\n",
    "            W[i], L[i], upper=False\n",
    "        ).solution  # C[i] = W[i] @ D_prev^-T, trsm()\n",
    "        D = W[i + 1] - torch.mm(C[i].t(), C[i])  # D = W[i+1] - C[i] @ C[i]^T, syrk()\n",
    "        L[i + 1] = torch.cholesky(D)\n",
    "    return L, C\n",
    "\n",
    "\n",
    "def block_tri_cholesky_solve(L, C, B):\n",
    "    \"\"\"Blockwise cholesky solve for a size varing block tridiagonal matrix.\n",
    "\n",
    "    Args:\n",
    "        L (List[torch.Tensor]): List of lower triangular blocks.\n",
    "        C (List[torch.Tensor]): List of diagonal blocks.\n",
    "        B (torch.Tensor): RHS.\n",
    "\n",
    "    Returns:\n",
    "        X (torch.Tensor): Solution.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(L)\n",
    "    X = torch.zeros_like(B)\n",
    "    for i in range(n):\n",
    "        X[:, i * C[i].size(-1) : (i + 1) * C[i].size(-1)] = torch.cholesky_solve(\n",
    "            B[:, i * C[i].size(-1) : (i + 1) * C[i].size(-1)],\n",
    "            L[i + 1] + torch.mm(C[i].t(), C[i]),\n",
    "        )\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Your functions here...\n",
    "\n",
    "\n",
    "def generate_block_tridiagonal(n: int, block_size: int) -> list[torch.Tensor]:\n",
    "    \"\"\"Generate a random block tridiagonal matrix.\"\"\"\n",
    "    blocks = [torch.randn(block_size, block_size) for _ in range(n)]\n",
    "    for block in blocks:\n",
    "        block += block.t()  # Make it symmetric\n",
    "        block += block_size * torch.eye(block_size)  # Make it positive definite\n",
    "    return blocks\n",
    "\n",
    "\n",
    "# Generate a random block tridiagonal matrix\n",
    "n = 5\n",
    "block_size = 3\n",
    "blocks = generate_block_tridiagonal(n, block_size)\n",
    "\n",
    "# Perform blockwise Cholesky factorization\n",
    "L, C = block_tri_cholesky(blocks)\n",
    "\n",
    "# Generate a random RHS\n",
    "B = torch.randn(n * block_size)\n",
    "\n",
    "# Perform blockwise Cholesky solve\n",
    "X_block = block_tri_cholesky_solve(L, C, B)\n",
    "\n",
    "# Perform standard Cholesky factorization and solve\n",
    "A = torch.zeros(n * block_size, n * block_size)\n",
    "for i in range(n):\n",
    "    A[i * block_size : (i + 1) * block_size, i * block_size : (i + 1) * block_size] = blocks[i]\n",
    "    if i < n - 1:\n",
    "        A[i * block_size : (i + 1) * block_size, (i + 1) * block_size : (i + 2) * block_size] = (\n",
    "            blocks[i]\n",
    "        )\n",
    "        A[(i + 1) * block_size : (i + 2) * block_size, i * block_size : (i + 1) * block_size] = (\n",
    "            blocks[i]\n",
    "        )\n",
    "L_full = torch.cholesky(A)\n",
    "X_full = torch.cholesky_solve(B.unsqueeze(1), L_full).squeeze()\n",
    "\n",
    "# Compare the results\n",
    "print(\"Blockwise solution:\", X_block)\n",
    "print(\"Full solution:\", X_full)\n",
    "print(\"Difference:\", torch.norm(X_block - X_full))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplacian-Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cuda.preferred_linalg_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(3, 4).clamp_min(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ll = torch.concat([torch.diag(w.sum(dim=1)), w.T], dim=0)\n",
    "Lr = torch.concat((w, torch.diag(w.sum(dim=0))), dim=0)\n",
    "L = torch.concat((Ll, Lr), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lp = L + torch.eye(7) * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_2 = torch.linalg.cholesky(Lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1, info1 = torch.linalg.cholesky_ex(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_3, info2 = torch.linalg.cholesky_ex(Lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(c_2, c_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(c_3 - c_2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = torch.linalg.cond(Lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAPACK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://netlib.org/lapack/explore-html/da/dba/group__double_o_t_h_e_rcomputational_gae5d8ecd7fbd852fe3c3f71e08ec8332c.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import scipy.linalg as sla\n",
    "\n",
    "# generate a random positive semi-definite matrix\n",
    "n = 3\n",
    "A = np.random.randn(n, n)\n",
    "B = A @ A.T\n",
    "left, v = sla.eigh(B)\n",
    "C = B - left[0] * v[:, 0:1] @ [v[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize the matrix with Cholesky decomposition\n",
    "U = nla.cholesky(C + np.eye(n) * 1e-7)\n",
    "\n",
    "# compare with lapack wrapper\n",
    "U2, piv, rank, info = sla.lapack.dpstf2(C + np.eye(n) * 1e-7)\n",
    "print(info)\n",
    "U3 = nla.cholesky(C + np.eye(n) * 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(U - U3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.linalg as tla\n",
    "\n",
    "tB = torch.from_numpy(C)\n",
    "L, piv = tla.cholesky_ex(tB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tla.cond(tB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(tB, L @ L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tla.cholesky_ex(tB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tla.cholesky(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "nla.cholesky(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sla.lapack.spstf2(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.eye(U2.shape[0])[piv - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(P @ U2.T, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tla.eigvalsh(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = B - left[0] * v[:, 0:1] @ [v[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tla.expm_cond(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L @ L.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use julia bindings\n",
    "import julia\n",
    "\n",
    "julia.install()\n",
    "from julia import Base\n",
    "\n",
    "Base.sind(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(1, 1, 8, 8)  # batch size, channels, height, width\n",
    "convlayer = nn.Conv2d(1, 3, 3, 1, bias=False)  # in_channels, out_channels, kernel_size, stride\n",
    "\n",
    "\n",
    "def conv2d(x, w):\n",
    "    return torch.einsum(\"bchw, oihw -> bco\", x, w)\n",
    "\n",
    "\n",
    "# check if the output is the same\n",
    "torch.allclose(conv2d(x, convlayer.weight), convlayer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convlayer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maxpool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use gumbel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to avgpool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"./logs/train/runs/2023-07-06_21-52-51/checkpoints/last.ckpt\"\n",
    "# load weight from checkpoint\n",
    "model = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get(\"state_dict\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = model.get(\"state_dict\").get(\"net.model.lin1.weight\")\n",
    "w2 = model.get(\"state_dict\").get(\"net.model.last.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = w1[:, ::2] - w1[:, 1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = wt.sum(dim=0).reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(wt.numpy(), interpolation=\"nearest\", cmap=\"seismic\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(w2.numpy(), interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a46654922a4325f3c08572184af70d13caa3bc46da3b244c5f3d5e106718b6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
