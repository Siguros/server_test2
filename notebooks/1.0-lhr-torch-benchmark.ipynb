{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref) https://pytorch.org/tutorials/recipes/recipes/benchmark.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Benchmarking a single operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagmul(mat, diag):\n",
    "    return mat * diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "import torch\n",
    "\n",
    "A = torch.randn(256, 256)\n",
    "d = torch.randn(256)\n",
    "num_threads = torch.get_num_threads()\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"torch.matmul(A, torch.diag(d))\", globals={\"d\": d, \"A\": A}, num_threads=num_threads\n",
    ").blocked_autorange(min_run_time=1)\n",
    "t1 = benchmark.Timer(\n",
    "    stmt=\"diagmul(d, A)\",\n",
    "    setup=\"from __main__ import diagmul\",\n",
    "    globals={\"d\": d, \"A\": A},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A * d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matmul: \", t0)\n",
    "print(\"Diagmul: \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = benchmark.Timer(\n",
    "    stmt=\"d.mul(A)\", globals={\"d\": d, \"A\": A}, num_threads=num_threads\n",
    ").blocked_autorange(min_run_time=1)\n",
    "print(\"Matmul: \", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "results = []\n",
    "sizes = [1, 64, 1024]\n",
    "for m, n in product(sizes, sizes):\n",
    "    # label and sub_label are the rows\n",
    "    # description is the column\n",
    "    label = \"Diagonal matrix multiplication\"\n",
    "    sub_label = f\"[{m}, {n}]\"\n",
    "    A = torch.rand((m, n))\n",
    "    d = torch.rand(n)\n",
    "    for num_threads in [1, 4, 8]:\n",
    "        results.append(\n",
    "            benchmark.Timer(\n",
    "                stmt=\"torch.matmul(A, torch.diag(d))\",\n",
    "                globals={\"d\": d, \"A\": A},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description=\"mm\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "        )\n",
    "        results.append(\n",
    "            benchmark.Timer(\n",
    "                stmt=\"diagmul(A,d)\",\n",
    "                setup=\"from __main__ import diagmul\",\n",
    "                globals={\"d\": d, \"A\": A},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description=\"vm\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "        )\n",
    "\n",
    "compare = benchmark.Compare(results)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.utils import eqprop_utils\n",
    "\n",
    "\n",
    "def layer_power_1(G, in_v, out_v):\n",
    "    \"\"\"Calculate sum_{i,j} G_{ij}*(in_v_i - out_v_j)^2\"\"\"\n",
    "    return torch.sum(G.mT * eqprop_utils.deltaV(in_v, out_v).pow(2), dim=(1, 2))\n",
    "\n",
    "\n",
    "def layer_power_2(G, in_v, out_v):\n",
    "    \"\"\"Calculate sum_{i,j} G_{ij}*(in_v_i - out_v_j)^2\"\"\"\n",
    "    in_v = in_v.unsqueeze(1)\n",
    "    out_v = out_v.unsqueeze(2)\n",
    "    return (\n",
    "        torch.bmm(in_v.pow(2), G).sum(dim=(1, 2))\n",
    "        + torch.bmm(G, out_v.pow(2)).sum(dim=(1, 2))\n",
    "        - 2 * (in_v @ G @ out_v).squeeze()\n",
    "    )\n",
    "\n",
    "\n",
    "shape = (64, 512, 256)\n",
    "G = torch.randn(shape)\n",
    "in_v = torch.randn(shape[0], shape[1])\n",
    "out_v = torch.randn(shape[0], shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(layer_power_1(G, in_v, out_v), layer_power_2(G, in_v, out_v), atol=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = benchmark.Timer(\n",
    "    stmt=\"torch.bmm(in_v.unsqueeze(1).pow(2), G).sum(dim=(1,2))\",\n",
    "    globals={\"G\": G, \"in_v\": in_v, \"out_v\": out_v},\n",
    "    num_threads=1,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "t4 = benchmark.Timer(\n",
    "    stmt=\"torch.bmm(G, out_v.unsqueeze(2).pow(2)).squeeze().sum(dim=(1))\",\n",
    "    globals={\"G\": G, \"in_v\": in_v, \"out_v\": out_v},\n",
    "    num_threads=1,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "print(\"sum 2d: \", t3)\n",
    "print(\"squeeze and sum: \", t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "num_threads = torch.get_num_threads()\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"layer_power_1(G, in_v, out_v)\",\n",
    "    setup=\"from __main__ import layer_power_1\",\n",
    "    globals={\"in_v\": in_v, \"out_v\": out_v, \"G\": G},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "t1 = benchmark.Timer(\n",
    "    stmt=\"layer_power_2(G, in_v, out_v)\",\n",
    "    setup=\"from __main__ import layer_power_2\",\n",
    "    globals={\"in_v\": in_v, \"out_v\": out_v, \"G\": G},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "\n",
    "print(\"layer_power_1: \", t0)\n",
    "print(\"layer_power_2: \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "results = []\n",
    "sizes = [64, 256, 1024]\n",
    "for m, n in product(sizes, sizes):\n",
    "    # label and sub_label are the rows\n",
    "    # description is the column\n",
    "    label = \"Layer power\"\n",
    "    sub_label = f\"[{m}, {n}]\"\n",
    "    shape = (64, m, n)\n",
    "    G = torch.randn(shape)\n",
    "    in_v = torch.randn(shape[0], shape[1])\n",
    "    out_v = torch.randn(shape[0], shape[2])\n",
    "    for num_threads in [1, 4, 8]:\n",
    "        results.append(\n",
    "            benchmark.Timer(\n",
    "                stmt=\"layer_power_1(G, in_v, out_v)\",\n",
    "                setup=\"from __main__ import layer_power_1\",\n",
    "                globals={\"in_v\": in_v, \"out_v\": out_v, \"G\": G},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description=\"deltaV\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "        )\n",
    "        results.append(\n",
    "            benchmark.Timer(\n",
    "                stmt=\"layer_power_2(G, in_v, out_v)\",\n",
    "                setup=\"from __main__ import layer_power_2\",\n",
    "                globals={\"in_v\": in_v, \"out_v\": out_v, \"G\": G},\n",
    "                num_threads=num_threads,\n",
    "                label=label,\n",
    "                sub_label=sub_label,\n",
    "                description=\"sq+sq-prod\",\n",
    "            ).blocked_autorange(min_run_time=1)\n",
    "        )\n",
    "\n",
    "compare = benchmark.Compare(results)\n",
    "compare.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update diag elements in batched matrix\n",
    "import torch\n",
    "\n",
    "A = torch.ones(2, 3, 3)\n",
    "v = torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "A.diagonal(dim1=1, dim2=2)[:] += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eqprop grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# from src.utils import eqprop_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad1(in_V_free, out_V_free, in_V, out_V):\n",
    "    \"\"\"Calculate the gradient of the layer power with respect to the free variables\"\"\"\n",
    "    free_dV = eqprop_utils.deltaV(in_V_free, out_V_free)\n",
    "    nudge_dV = eqprop_utils.deltaV(in_V, out_V)\n",
    "    return nudge_dV.pow(2).mean(dim=0) - free_dV.pow(2).mean(dim=0)\n",
    "\n",
    "\n",
    "def grad2(\n",
    "    in_V_free: torch.Tensor, out_V_free: torch.Tensor, in_V: torch.Tensor, out_V: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    res = 2 * (\n",
    "        torch.bmm(out_V_free.unsqueeze(2), in_V_free.unsqueeze(1)).squeeze().mean(dim=0)\n",
    "        - torch.bmm(out_V.unsqueeze(2), in_V.unsqueeze(1)).squeeze().mean(dim=0)\n",
    "    )\n",
    "    res += in_V.pow(2).mean(dim=0) - in_V_free.pow(2).mean(dim=0)\n",
    "    res += (out_V.pow(2).mean(dim=0) - out_V_free.pow(2).mean(dim=0)).unsqueeze(1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad3 = torch.jit.script(grad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_in = (128, 1024)\n",
    "shape_out = (128, 512)\n",
    "in_V_free = torch.randn(shape_in)\n",
    "out_V_free = torch.randn(shape_out)\n",
    "in_V = torch.randn(shape_in)\n",
    "out_V = torch.randn(shape_out)\n",
    "\n",
    "# torch.allclose(grad1(in_V_free, out_V_free, in_V, out_V), grad2(in_V_free, out_V_free, in_V, out_V), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "num_threads = torch.get_num_threads()\n",
    "t1 = benchmark.Timer(\n",
    "    stmt=\"grad2(in_V_free, out_V_free, in_V, out_V)\",\n",
    "    setup=\"from __main__ import grad2\",\n",
    "    globals={\"in_V_free\": in_V_free, \"out_V_free\": out_V_free, \"in_V\": in_V, \"out_V\": out_V},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"grad3(in_V_free, out_V_free, in_V, out_V)\",\n",
    "    setup=\"from __main__ import grad3\",\n",
    "    globals={\"in_V_free\": in_V_free, \"out_V_free\": out_V_free, \"in_V\": in_V, \"out_V\": out_V},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "\n",
    "\n",
    "print(\"layer_power_3: \", t0)\n",
    "print(\"layer_power_2: \", t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalar division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "A = torch.randn(1024, 256)\n",
    "beta = torch.rand(1)\n",
    "num_threads = torch.get_num_threads()\n",
    "t0 = benchmark.Timer(\n",
    "    stmt=\"A/beta\", globals={\"beta\": beta, \"A\": A}, num_threads=num_threads\n",
    ").blocked_autorange(min_run_time=1)\n",
    "t1 = benchmark.Timer(\n",
    "    stmt=\"A*(1/beta)\",\n",
    "    globals={\"beta\": beta, \"A\": A},\n",
    "    num_threads=num_threads,\n",
    ").blocked_autorange(min_run_time=1)\n",
    "print(\"A/beta: \", t0)\n",
    "print(\"A*(1/beta): \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
