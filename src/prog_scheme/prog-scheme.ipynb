{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form log list[string], search Error: {err_normalized} pattern and extract the value\n",
    "# into list\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.utils.logging_utils import LogCapture\n",
    "\n",
    "\n",
    "def extract_error(log_list, prefix: str = \"Error: \") -> list:\n",
    "    err_list = []\n",
    "    for log in log_list:\n",
    "        if prefix in log:\n",
    "            err_list.append(float(re.findall(prefix + r\"([0-9.e-]+)\", log)[0]))\n",
    "\n",
    "    return err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_singular_values(Ws: tuple[torch.Tensor]):\n",
    "    for w in Ws:\n",
    "        s = torch.linalg.svdvals(w)\n",
    "        plt.plot(s)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Singular Value Index\")\n",
    "    plt.ylabel(\"Singular Value\")\n",
    "    plt.title(\"Singular Values of Weight Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "output_size = 50\n",
    "batch_size = 1\n",
    "\n",
    "tol = 1e-4\n",
    "max_iter = 1000\n",
    "\n",
    "# generate low rank matrix\n",
    "rank = 5\n",
    "w = torch.randn(input_size, output_size)\n",
    "w.clamp_(-1, 1)\n",
    "if rank < min(w.shape):\n",
    "    u, s, v = torch.svd(w)\n",
    "    w = torch.mm(u[:, :rank], torch.mm(torch.diag(s[:rank]), v[:, :rank].t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnalogTile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aihwkit.simulator.configs import FloatingPointRPUConfig, SingleRPUConfig\n",
    "from aihwkit.simulator.configs.devices import (\n",
    "    ConstantStepDevice,\n",
    "    DriftParameter,\n",
    "    ExpStepDevice,\n",
    "    FloatingPointDevice,\n",
    "    IdealDevice,\n",
    "    SimpleDriftParameter,\n",
    ")\n",
    "from aihwkit.simulator.configs.utils import (\n",
    "    InputRangeParameter,\n",
    "    PrePostProcessingParameter,\n",
    "    UpdateParameters,\n",
    ")\n",
    "from aihwkit.simulator.parameters.enums import PulseType\n",
    "from aihwkit.simulator.presets.configs import IdealizedPreset, PCMPreset, ReRamSBPreset\n",
    "from aihwkit.simulator.presets.devices import IdealizedPresetDevice\n",
    "from aihwkit.simulator.tiles import FloatingPointTile\n",
    "from aihwkit.simulator.tiles.analog import AnalogTile\n",
    "\n",
    "# pre_post_cfg = PrePostProcessingParameter(input_range=InputRangeParameter(enable=True))\n",
    "device_cfg = ExpStepDevice()\n",
    "# device_cfg = IdealDevice()\n",
    "update_cfg = UpdateParameters(pulse_type=PulseType.MEAN_COUNT)\n",
    "rpuconfig = SingleRPUConfig(update=update_cfg, device=device_cfg)\n",
    "# rpuconfig.forward.is_perfect = True\n",
    "rpuconfig.device.w_max_dtod = 0\n",
    "rpuconfig.device.w_min_dtod = 0\n",
    "# rpuconfig = SingleRPUConfig()\n",
    "atile = AnalogTile(output_size, input_size, rpu_config=rpuconfig)  # with periphery\n",
    "atile_dic = {}\n",
    "atile.state_dict(atile_dic)\n",
    "atile2 = AnalogTile(output_size, input_size, rpu_config=rpuconfig)\n",
    "atile2.load_state_dict(atile_dic, assign=True)\n",
    "atile3 = AnalogTile(output_size, input_size, rpu_config=rpuconfig)\n",
    "atile3.load_state_dict(atile_dic, assign=True)\n",
    "print(rpuconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpuconfig.device.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(atile2.tile.get_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aihwkit.simulator.tiles.periphery import TileWithPeriphery\n",
    "\n",
    "from src.prog_scheme.program_methods import gdp2, svd, svd_ekf\n",
    "\n",
    "# enroll the programming methods\n",
    "atile.program_weights = gdp2.__get__(atile, TileWithPeriphery)\n",
    "atile2.program_weights = svd.__get__(atile2, TileWithPeriphery)\n",
    "atile3.program_weights = svd_ekf.__get__(atile3, TileWithPeriphery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogCapture() as logc:\n",
    "    atile.tile.set_weights(w.clone().T)\n",
    "    atile.program_weights(batch_size=batch_size, tolerance=tol, max_iter=max_iter)\n",
    "    log_list1 = logc.get_log_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogCapture() as logc:\n",
    "    # atile2.set_weights(weight=w, realistic=True)\n",
    "    atile2.tile.set_weights(w.clone().double().T)\n",
    "    atile2.program_weights(max_iter=max_iter, tolerance=tol, svd_once=False)\n",
    "    log_list2 = logc.get_log_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LogCapture() as logc:\n",
    "#     atile3.tile.set_weights(w.clone().T)\n",
    "#     atile3.program_weights(tolerance=1e-10, max_iter=10)\n",
    "#     log_list3 = logc.get_log_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = (\n",
    "    w.T - atile.tile.get_weights(),\n",
    "    w.T - atile2.tile.get_weights(),\n",
    "    # w.T - atile3.tile.get_weights(),\n",
    ")\n",
    "plot_singular_values(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"nuclear norm of \\n\"\n",
    "    f\"atile: {torch.linalg.matrix_norm(W[0], ord='nuc')},\\n\"\n",
    "    f\"atile2: {torch.linalg.matrix_norm(W[1], ord='nuc')},\\n\"\n",
    "    # f\"atile3: {torch.linalg.matrix_norm(W[2], ord='nuc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list1[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log in [log_list1, log_list2]:\n",
    "    err = extract_error(log)\n",
    "    plt.semilogy(err)\n",
    "# set legend\n",
    "plt.legend([f\"gdp-seq(batchsize {batch_size})\", \"svd\"])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Nuclear norm of weight error (sum of singular values)\")\n",
    "plt.title(\"Error vs Iteration @ {}x{}, rank={}\".format(input_size, output_size, rank))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpuconf2dict(rpuconfig, max_depth=2, current_depth=0):\n",
    "    if current_depth > max_depth:\n",
    "        return rpuconfig\n",
    "    result = {}\n",
    "    for key, val in rpuconfig.__dict__.items():\n",
    "        if isinstance(val, (float, int, str, bool)):\n",
    "            result[key] = val\n",
    "        elif isinstance(val, type):\n",
    "            result[key] = repr(val)\n",
    "        else:\n",
    "            result[key] = rpuconf2dict(val, max_depth, current_depth + 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    **rpuconf2dict(rpuconfig, max_depth=1),\n",
    "    \"matrix\": {\"input_size\": input_size, \"output_size\": output_size, \"rank\": rank},\n",
    "    \"methods\": {\"tolerance\": tol, \"max_iter\": max_iter, \"batch_size\": batch_size},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "\n",
    "with wandb.init(project=\"prog-scheme\", entity=\"spk\", config=conf, dir=\"../../logs\") as run:\n",
    "    err1 = extract_error(log_list1)  # GDP error\n",
    "    err2 = extract_error(log_list2)  # SVD error\n",
    "\n",
    "    # Determine the maximum length\n",
    "    max_length = max(len(err1), len(err2))\n",
    "\n",
    "    # Pad the shorter list with zeros\n",
    "    err1 = np.pad(err1, (0, max_length - len(err1)), \"constant\")\n",
    "    err2 = np.pad(err2, (0, max_length - len(err2)), \"constant\")\n",
    "\n",
    "    iterations = np.arange(max_length)\n",
    "\n",
    "    # Create a single wandb.Table with both GDP and SVD errors\n",
    "    combined_table = wandb.Table(\n",
    "        data=[[i, e1, e2] for i, e1, e2 in zip(iterations, err1, err2)],\n",
    "        columns=[\"iteration\", \"GDP_error\", \"SVD_error\"],\n",
    "    )\n",
    "\n",
    "    # Create a line plot with both GDP and SVD errors\n",
    "    error_plot = wandb.plot.line(\n",
    "        table=combined_table,\n",
    "        x=\"iteration\",\n",
    "        y=[\"GDP_error\", \"SVD_error\"],\n",
    "        title=\"GDP vs SVD Error Comparison\",\n",
    "    )\n",
    "\n",
    "    run.log({\"error_comparison\": error_plot})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP batch-size effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_size_ in [1, 5, 10, 20, 50, input_size]:\n",
    "    with LogCapture() as logc:\n",
    "        atile.tile.set_weights(w.T)\n",
    "        atile.program_weights(batch_size=batch_size_)\n",
    "        log_list = logc.get_log_list()\n",
    "    err_list = extract_error(log_list)\n",
    "    num_iter = len(err_list)\n",
    "    plt.semilogy(err_list, label=f\"batch_size={batch_size_}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Nuclear norm of weight error\")\n",
    "plt.title(\n",
    "    \"{}x{} rank={} matrix with {}\".format(\n",
    "        input_size, output_size, rank, atile.rpu_config.device.__class__.__name__\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d2d variaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataclass fields\n",
    "atile.rpu_config.device.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.T[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the element wise perturbation is applied\n",
    "\n",
    "atile.tile.set_weights(w.T)\n",
    "wtile = atile.tile.get_weights()\n",
    "torch.allclose(wtile, w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomTile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aihwkit.simulator.tiles.custom import CustomTile\n",
    "\n",
    "ctile = CustomTile(output_size, input_size)\n",
    "ctile.get_weights(realistic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RealisticTile(Ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prog_scheme.realistic import RealisticTile, RPUConfigwithProgram\n",
    "\n",
    "rpu_config = RPUConfigwithProgram(program_weights=gdp2)\n",
    "ctile = RealisticTile(output_size, input_size, rpu_config=rpu_config)\n",
    "\n",
    "rpu_config2 = RPUConfigwithProgram(program_weights=svd)\n",
    "ctile2 = RealisticTile(output_size, input_size, rpu_config=rpu_config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rpu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LogCapture() as logc:\n",
    "    ctile.set_weights(w, realistic=True)\n",
    "    log_list = logc.get_log_list()\n",
    "\n",
    "with LogCapture() as logc:\n",
    "    ctile2.set_weights(w, realistic=True)\n",
    "    log_list2 = logc.get_log_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract error and plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "err_list = extract_error(log_list)\n",
    "err_list2 = extract_error(log_list2)\n",
    "\n",
    "plt.plot(err_list, label=\"gpc\")\n",
    "plt.plot(err_list2, label=\"svd\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error vs Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only `AnalogTile` which inherits `TileWithPeriphery` class has `program_weights` method\n",
    "\n",
    "`program_weights` method implements \"Gradient descent-based programming of analog in-memory computing cores\" by default\n",
    "\n",
    "`set_weights` method is used to set the weights of the analog tile to the given values\\\n",
    "`program_weights` method is internally called by `set_weights` method to program the weights of the analog tile\\\n",
    "\n",
    "`get_weights` method is used to get the weights of the analog tile\\\n",
    "`read_weights` method is used to read the weights of the analog tile with read noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aihwkit.nn import AnalogLinear\n",
    "from aihwkit.optim import AnalogSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_layer = torch.nn.Linear(input_size, output_size, bias=False)\n",
    "layer = AnalogLinear.from_digital(digital_layer, rpuconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AnalogSGD(layer.parameters(), lr=0.005)\n",
    "losses = []\n",
    "for _ in range(1000):\n",
    "    x = torch.rand(input_size)\n",
    "    yhat = layer(x)\n",
    "    loss = (yhat**2).sum()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
